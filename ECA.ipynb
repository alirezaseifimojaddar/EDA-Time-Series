{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part--1 Defining CHICAGO CRIMES Dataset. And our Goals.\n",
    "This dataset reflects reported incidents of crime that occurred in the City of Chicago from 2001 to present, Data is extracted from the Chicago Police Department's CLEAR (Citizen Law Enforcement Analysis and Reporting) system.\n",
    "We will go through Exploratory Data Analysis first, Then we will Do some Time Series Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import pydeck as pdk\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's visualize and possibily gain some insights about null values and data gathering process, for this we use missingno library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we load the dataset initially, take a look at it, and after that we can decide about the procedure of cleaning our dataset, besides it is always a good idea to deeply take a look at the null values using \"missingno\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Crimes_-_2001_to_Present.csv\", low_memory=False) # loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5) # we have 22 columns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() # let's see the missing values per column,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape # Here we see that we are dealing with more than 7M rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # this return column names also dtypes of the columns,\n",
    "          # also the Dataframes memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns) # this way we can also take a look at the column\n",
    "                 # names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations about the data.\n",
    "From the above cells we can observe that there are 22 columns and well over 7.2 million rows, we also see the data type values for every column.\n",
    "The Date column may need to be changed to python's datatime.datetime format to extract the month, time and day of the week information.\n",
    "# some of the columns in the dataset overlap in importance so it would not make sense to keep all of them in our final dataframe configuration. We will handle this in the future though.\n",
    "# It is bad practice to feed this kind of bloated configuration into a machine learning (ML) task as it does not help the model generalize well on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are dealing with a real world dataset, It is common that we see missing values in the dataset. To build a good machine learning model  we need to have a good understanding of how the NaN values are distributed in our dataset.\n",
    "\n",
    "Missingno library offers a very nice way to visualize the distribution of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize missing values as a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using matrix can very quickly find the pattern of missingness in the dataset. The columns X Coordinate/Y Coordinate/Latitude/Longitude and location have a similar pattern of missing values while others shows a different pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAR chart gives an idea about how many missing values are there in each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It shows bars that are proportional to the number of non-missing values as well as providing the actual number of non-missing values. We get an idea of how much of each column is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HEATMAP shows the correlation of missingness between every 2 columns. In our example,  the correlation between X Coordinate and Latitude is 1 which means if one of them is present then the other one must be present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A value near -1 means if one variable appears then the other variable is very likely to be missing.\n",
    "A value near 0 means there is no dependence between the occurrence of missing values of two variables.\n",
    "A value near 1 means if one variable appears then the other variable is very likely to be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are plotting dendrogram which shows hierarchical cluster creation based on missing values correlation between various datasets. The columns of the dataset which have a deep connection in missing values between them will be kept in the same cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we can also visualize this using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df.isnull(), cbar = False, cmap = \"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that the most null values are for years 2001 and 2002 ..., perhaps due to lack of organization mostly latitudes and longitudes and X/Y coordiantes also ward etc are missing in the starting days of this dataset. After that we see that the dataset gets better and better in terms of being solid in capturing latitudes and longitudes of each record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have a basic understanding regarding null values and the structure of the dataset, we can write a class to Load The Dataset, also we can write some methods to handle transforming and cleaning the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformer():\n",
    "    def __init__(self, dataframe_path, nrows):\n",
    "        self.nrows = nrows\n",
    "        self.dataframe = pd.read_csv(dataframe_path,\n",
    "                                    nrows=self.nrows,\n",
    "                                    low_memory=False)\n",
    "        \n",
    "    def transformer(self):\n",
    "        # Transforming Date column from object to datetime\n",
    "        self.dataframe[\"Date\"] = pd.to_datetime(self.dataframe[\"Date\"])\n",
    "        # Extracting meaningful data form Date Column which is now in datetime format.\n",
    "        self.dataframe[\"month\"] = self.dataframe[\"Date\"].dt.month\n",
    "        self.dataframe[\"day_of_month\"] = self.dataframe[\"Date\"].dt.day\n",
    "        self.dataframe[\"day_of_year\"] = self.dataframe[\"Date\"].dt.dayofyear\n",
    "        self.dataframe[\"day_of_week\"] = self.dataframe[\"Date\"].dt.dayofweek\n",
    "        self.dataframe[\"hour_of_day\"] = self.dataframe[\"Date\"].dt.hour\n",
    "        #Turning All the Columns to Lowercase.\n",
    "        lowercase = lambda x: x.replace(\" \", \"_\").lower()\n",
    "        self.dataframe.rename(lowercase, axis=\"columns\", inplace=True)\n",
    "         \n",
    " \n",
    "    \n",
    "    def cleaning(self):\n",
    "        self.transformer()\n",
    "        # In some tests we see a few point outside the chicago region\n",
    "        # so it's better to remove those points\n",
    "        self.dataframe = self.dataframe[\n",
    "            (self.dataframe.latitude >= 41.64) & (self.dataframe.longitude <= -87.50)  \n",
    "        ]\n",
    "        \n",
    "        # In the dataset we see that there are 23 point that have x_coordinate and y_coordinate\n",
    "        # set to zero wich is wise to remove them.\n",
    "        # data[data['y_coordinate'] == 0] == data[data['x_coordinate'] == 0] #23 rows Ã— 26 columns\n",
    "        self.dataframe[['x_coordinate', 'y_coordiante']] = self.dataframe[['x_coordinate', 'y_coordinate']].replace(0.0, np.nan)\n",
    "        self.dataframe.dropna(inplace=True)\n",
    "        \n",
    "        # in the dataset we have to ways of getting the year\n",
    "        # one way in through dataset[\"date\"].dt.year\n",
    "        # The other way is to use the year column. dataset.year\n",
    "        # let's verify that these two values are equal if not we will filter them out from our dataset.\n",
    "        self.dataframe[self.dataframe[\"date\"].dt.year == self.dataframe.year]\n",
    "        \n",
    "        # it is always good to filter out the possibility of duplicates.\n",
    "        self.dataframe.drop_duplicates(subset=['id', 'case_number'], inplace=True)\n",
    "\n",
    "        return self.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataTransformer(\"Crimes_-_2001_to_Present.csv\",7245927).cleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part--2 EDA SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Explore the dataset in order to find some trends, also some meaningful phenomenon.\n",
    "In this part we try to answer some questions and catch some patters. On our way data visualization techniques will come to our hand, mostly we will use seaborn and plotly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's take a look at Categories of crime in Chicago"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the common crimes include THEFT, BATTERY, and CRIMINAL DAMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"primary_type\"].value_counts() # let's plot this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "fig = px.bar(data[\"primary_type\"].value_counts())\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that Theft and Battery are among the most crimes commited over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's a good idea to look at the Crime Trends over these years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's focus on the crime variables which are stores in the primary_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"primary_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"primary_type\"].unique()) # we can see that we are dealing with 35 different crimes\n",
    "                                   # in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's visualize all the crimes based on crime's latitude and longitude, for this we use seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'longitude', \n",
    "           y = 'latitude',data=data,fit_reg=False, hue=\"district\",palette='Paired',height=100,\n",
    "           ci=3,scatter_kws={\"marker\": \"D\", \n",
    "                        \"s\": 10, \"alpha\": 0.9})\n",
    "ax = plt.gca()\n",
    "ax.set_title(\"All Crime Distribution per District\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# geographical distribution scatter plots by crime\n",
    "g = sns.lmplot(x=\"longitude\",y=\"latitude\",col=\"primary_type\",hue=\"district\",data=data, \n",
    "               col_wrap=4, height=10, fit_reg=False, sharey=False, palette='Paired',ci=3,\n",
    "               scatter_kws={\"marker\": \"D\",\n",
    "                            \"s\": 2, \"alpha\": 0.9})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "high homicide rates are clustered on the top left and middle bottom of the scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's further look at the top crimes in the city over the years. probably we can catch some neat trends in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the Yearly Theft, Battery, Criminal Damage, and NARCOTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='year',\n",
    "            y='THEFT',\n",
    "            color=\"year\",\n",
    "            ci=1,\n",
    "            data=data.groupby(['year'])['primary_type'].value_counts().unstack().reset_index(),\n",
    "            palette='husl').\\\n",
    "            set_title(\"CHICAGO THEFT RATES: 2001 - 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='year',\n",
    "            y='CRIMINAL DAMAGE',\n",
    "            color=\"year\",\n",
    "            linewidth=4,\n",
    "            ci=1,\n",
    "            data=data.groupby(['year'])['primary_type'].value_counts().unstack().reset_index(),\n",
    "            palette='rocket').\\\n",
    "            set_title(\"CHICAGO CRIMINAL DAMAGE RATES: 2001 - 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='year',\n",
    "            y='BATTERY',\n",
    "            color=\"year\",\n",
    "            ci=1,\n",
    "            data=data.groupby(['year'])['primary_type'].value_counts().unstack().reset_index(),\n",
    "            palette='Set2').\\\n",
    "            set_title(\"CHICAGO BATTERY RATES: 2001 - 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='year',\n",
    "            y='NARCOTICS',\n",
    "            color=\"year\",\n",
    "            ci=1,\n",
    "            data=data.groupby(['year'])['primary_type'].value_counts().unstack().reset_index(),\n",
    "            palette='tab10').\\\n",
    "            set_title(\"CHICAGO NARCOTICS RATES: 2001 - 2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x='year',\n",
    "            y='HOMICIDE',\n",
    "            color=\"year\",\n",
    "            ci=1,\n",
    "            data=data.groupby(['year'])['primary_type'].value_counts().unstack().reset_index(),\n",
    "            palette='hls').\\\n",
    "            set_title(\"CHICAGO HOMICIDE RATES: 2001 - 2020\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's also visualize Monthly Crime Rates, We can capture monthly trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "month_nms = ['January','February','March','April','May','June','July','August','September','October','November','December']    \n",
    "fig = sns.barplot(x='month',\n",
    "                  y='THEFT',\n",
    "                  data=data.groupby(['year','month'])['primary_type'].value_counts().unstack().reset_index(),palette=\"crest\")\n",
    "\n",
    "ax.set_xticklabels(month_nms)\n",
    "plt.title(\"CHICAGO THEFT RATES by MONTH -- All Years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "month_nms = ['January','February','March','April','May','June','July','August','September','October','November','December']    \n",
    "fig = sns.barplot(x='month',\n",
    "                  y='BATTERY',\n",
    "                  data=data.groupby(['year','month'])['primary_type'].value_counts().unstack().reset_index(),palette=\"husl\")\n",
    "\n",
    "ax.set_xticklabels(month_nms)\n",
    "plt.title(\"CHICAGO BATTERY RATES by MONTH -- All Years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "month_nms = ['January','February','March','April','May','June','July','August','September','October','November','December']    \n",
    "fig = sns.barplot(x='month',\n",
    "                  y='CRIMINAL DAMAGE',\n",
    "                  data=data.groupby(['year','month'])['primary_type'].value_counts().unstack().reset_index(),palette=\"viridis\")\n",
    "\n",
    "ax.set_xticklabels(month_nms)\n",
    "plt.title(\"CHICAGO CRIMINAL DAMAGE RATES by MONTH -- All Years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "month_nms = ['January','February','March','April','May','June','July','August','September','October','November','December']    \n",
    "fig = sns.barplot(x='month',\n",
    "                  y='NARCOTICS',\n",
    "                  data=data.groupby(['year','month'])['primary_type'].value_counts().unstack().reset_index(),palette=\"mako\")\n",
    "\n",
    "ax.set_xticklabels(month_nms)\n",
    "plt.title(\"CHICAGO NARCOTICS RATES by MONTH -- All Years\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "month_nms = ['January','February','March','April','May','June','July','August','September','October','November','December']    \n",
    "fig = sns.barplot(x='month',\n",
    "                  y='HOMICIDE',\n",
    "                  data=data.groupby(['year','month'])['primary_type'].value_counts().unstack().reset_index(),palette=\"flare\")\n",
    "\n",
    "ax.set_xticklabels(month_nms)\n",
    "plt.title(\"CHICAGO HOMICIDE RATES by MONTH -- All Years\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day of the Week Homicide Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "week_days = ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']    \n",
    "fig = sns.barplot(x='day_of_week',y='THEFT',data=data.groupby(['year','day_of_week'])['primary_type'].value_counts().unstack().reset_index(),palette='Set2')\n",
    "ax.set_xticklabels(week_days)\n",
    "plt.title('THEFT RATE BY DAY OF THE WEEK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "week_days = ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']    \n",
    "fig = sns.barplot(x='day_of_week',y='BATTERY',data=data.groupby(['year','day_of_week'])['primary_type'].value_counts().unstack().reset_index(),palette='husl')\n",
    "ax.set_xticklabels(week_days)\n",
    "plt.title('BATTERY RATE BY DAY OF THE WEEK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "week_days = ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']    \n",
    "fig = sns.barplot(x='day_of_week',y='CRIMINAL DAMAGE',data=data.groupby(['year','day_of_week'])['primary_type'].value_counts().unstack().reset_index(),palette='mako')\n",
    "ax.set_xticklabels(week_days)\n",
    "plt.title('CRIMINAL DAMAGE RATE BY DAY OF THE WEEK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "week_days = ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']    \n",
    "fig = sns.barplot(x='day_of_week',y='NARCOTICS',data=data.groupby(['year','day_of_week'])['primary_type'].value_counts().unstack().reset_index(),palette='rocket_r')\n",
    "ax.set_xticklabels(week_days)\n",
    "plt.title('NARCOTICS RATE DAY OF THE WEEK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "week_days = ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']    \n",
    "fig = sns.barplot(x='day_of_week',y='HOMICIDE',data=data.groupby(['year','day_of_week'])['primary_type'].value_counts().unstack().reset_index(),palette='rocket')\n",
    "ax.set_xticklabels(week_days)\n",
    "plt.title('HOMICIDE BY DAY OF THE WEEK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's also visualize Hourly Crime Rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "fig = sns.barplot(x='hour_of_day',y='THEFT',data=data.groupby(['year','hour_of_day'])['primary_type'].value_counts().unstack().reset_index(),palette='mako',alpha=.9)\n",
    "plt.title('THEFT BY HOUR OF THE DAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "fig = sns.barplot(x='hour_of_day',y='BATTERY',data=data.groupby(['year','hour_of_day'])['primary_type'].value_counts().unstack().reset_index(),palette='mako',alpha=.9)\n",
    "plt.title('BATTERY BY HOUR OF THE DAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "fig = sns.barplot(x='hour_of_day',y='CRIMINAL DAMAGE',data=data.groupby(['year','hour_of_day'])['primary_type'].value_counts().unstack().reset_index(),palette='mako',alpha=.9)\n",
    "plt.title('CRIMINAL DAMAGE BY HOUR OF THE DAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "fig = sns.barplot(x='hour_of_day',y='NARCOTICS',data=data.groupby(['year','hour_of_day'])['primary_type'].value_counts().unstack().reset_index(),palette='mako',alpha=.9)\n",
    "plt.title('NARCOTICS DAMAGE BY HOUR OF THE DAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,6))\n",
    "fig = sns.barplot(x='hour_of_day',y='HOMICIDE',data=data.groupby(['year','hour_of_day'])['primary_type'].value_counts().unstack().reset_index(),palette='mako',alpha=.9)\n",
    "plt.title('HOMICIDE BY HOUR OF THE DAY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.groupby(['year','district']).count().date.unstack().fillna(0)\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.heatmap(corr.dropna(axis=1), cbar_kws={'label': 'THEFT'}, annot=True,linewidths=0.2,cmap='Blues',robust=True,)\n",
    "plt.title('HOMICIDE vs DISTRICT vs YEAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = data.groupby(['year','district']).count().date.unstack().fillna(0)\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sns.set(font_scale=1.0)\n",
    "sns.heatmap(corr.dropna(axis=1), cbar_kws={'label': 'NARCOTICS'}, annot=True,linewidths=0.2,cmap='magma',robust=True,)\n",
    "plt.title('NARCOTICS vs DISTRICT vs YEAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most Dangerous & Least Dangerous Police Districts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LET'S take a look at the top places that crimes occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "sns.countplot(y= 'location_description', data = data, order = data['location_description'].value_counts().iloc[:10].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['district']).count().arrest.reset_index().sort_values(\"arrest\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context('notebook',font_scale=1.5):\n",
    "    sorted_homicides = data.groupby(['district']).count().arrest.reset_index().sort_values(\"arrest\", ascending=False)\n",
    "    fig, ax = plt.subplots(figsize=(20,6))\n",
    "    sns.barplot(x='district',\n",
    "                y='arrest',\n",
    "                data=sorted_homicides,\n",
    "                palette='magma',\n",
    "                order = list(sorted_homicides['district'].astype(int)),\n",
    "                label='big')\n",
    "    plt.title('ARREST PER DISTRICT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing with MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THEFT = data.groupby([\"primary_type\"]).get_group(\"THEFT\")\n",
    "BATTERY = data.groupby([\"primary_type\"]).get_group(\"BATTERY\")\n",
    "CRIMINAL_DAMAGE = data.groupby([\"primary_type\"]).get_group(\"CRIMINAL DAMAGE\")\n",
    "NARCOTICS= data.groupby([\"primary_type\"]).get_group(\"NARCOTICS\")\n",
    "HOMICIDE = data.groupby([\"primary_type\"]).get_group(\"HOMICIDE\")\n",
    "MOTOR_VEHICLE_THEFT = data.groupby([\"primary_type\"]).get_group(\"MOTOR VEHICLE THEFT\")\n",
    "ROBBERY = data.groupby([\"primary_type\"]).get_group(\"ROBBERY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 50))\n",
    "fig = px.density_mapbox(THEFT, lat='latitude', lon='longitude', z='district', radius=1,\n",
    "                        center=dict(lat=41.8781, lon=-87.6298), zoom=2,\n",
    "                        mapbox_style=\"stamen-watercolor\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 50))\n",
    "fig = px.density_mapbox(BATTERY, lat='latitude', lon='longitude', z='district', radius=1,\n",
    "                        center=dict(lat=41.8781, lon=-87.6298), zoom=8,\n",
    "                        mapbox_style=\"carto-darkmatter\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 50))\n",
    "fig = px.density_mapbox(CRIMINAL_DAMAGE, lat='latitude', lon='longitude', z='district', radius=1,\n",
    "                        center=dict(lat=41.8781, lon=-87.6298), zoom=8,\n",
    "                        mapbox_style=\"carto-darkmatter\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 50))\n",
    "fig = px.density_mapbox(NARCOTICS, lat='latitude', lon='longitude', z='district', radius=1,\n",
    "                        center=dict(lat=41.8781, lon=-87.6298), zoom=8,\n",
    "                        mapbox_style=\"carto-darkmatter\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 50))\n",
    "fig = px.density_mapbox(HOMICIDE, lat='latitude', lon='longitude', z='district', radius=1,\n",
    "                        center=dict(lat=41.8781, lon=-87.6298), zoom=8,\n",
    "                        mapbox_style=\"carto-darkmatter\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 50))\n",
    "fig = px.density_mapbox(MOTOR_VEHICLE_THEFT, lat='latitude', lon='longitude', z='district', radius=1,\n",
    "                        center=dict(lat=41.8781, lon=-87.6298), zoom=8,\n",
    "                        mapbox_style=\"carto-darkmatter\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 50))\n",
    "fig = px.density_mapbox(THEFT, lat='latitude', lon='longitude', z='district', radius=1,\n",
    "                        center=dict(lat=41.8781, lon=-87.6298), zoom=8,\n",
    "                        mapbox_style=\"carto-darkmatter\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import geopandas as gpd\n",
    "\n",
    "fig = px.scatter_geo(narcotics,\n",
    "                    lat=narcotics.latitude,\n",
    "                    lon=narcotics.longitude,\n",
    "                    color=narcotics.district,\n",
    "                    )\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.update_layout(\n",
    "        title = 'NARCOTICS MAP',\n",
    "        geo_scope=\"north america\", \n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}\n",
    "    \n",
    "    )\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kidnapping_df = data.groupby(\"primary_type\").get_group(\"KIDNAPPING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import geopandas as gpd\n",
    "\n",
    "fig = px.scatter_geo(kidnapping_df,\n",
    "                    lat=kidnapping_df.latitude,\n",
    "                    lon=kidnapping_df.longitude,\n",
    "                    color=kidnapping_df.district,\n",
    "                    )\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.update_layout(\n",
    "        title = 'HOMICIDE MAP',\n",
    "        geo_scope=\"north america\", \n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0}\n",
    "    \n",
    "    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import json\n",
    "chicago_geo = json.load(open(\"chicago_police_districts.geojson\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = data\n",
    "geojson = chicago_geo\n",
    "\n",
    "fig = px.choropleth(df, geojson=geojson, color=\"district\",\n",
    "                    locations=\"district\", featureidkey=\"properties.dist_num\",\n",
    "                    #projection=\"district\"\n",
    "                   )\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis. Part 2 of our Project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to predict the number of THEFT in Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = pd.DatetimeIndex(data.date) #setting the index to be the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"primary_type\"] = pd.Categorical(data[\"primary_type\"])\n",
    "data[\"location_description\"] = pd.Categorical(data[\"location_description\"])\n",
    "data[\"description\"] = pd.Categorical(data[\"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes # so we have changed primary_type / location_description / description\n",
    "            # from object to categorical and here we can see the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the crimes per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "data.resample(\"M\").size().plot(legend=False)\n",
    "plt.title(\"Rate of crimes per Month\")\n",
    "plt.xlabel(\"Months\")\n",
    "plt.ylabel(\"Crime Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "data.resample(\"D\").size().rolling(365).sum().plot(legend=False)\n",
    "plt.title(\"Rolling sum of crimes\")\n",
    "plt.xlabel(\"Number of Crimes\")\n",
    "plt.ylabel(\"Days\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "data.groupby([data.index.dayofweek]).size().plot(kind=\"barh\")\n",
    "plt.ylabel(\"Day of The Week\")\n",
    "plt.yticks(np.arange(7), days)\n",
    "plt.xlabel(\"Number Of Crimes\")\n",
    "plt.title(\"Crimes per Day of The Week\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "location_description = data.groupby([data[\"location_description\"]]).size().sort_values(ascending=False)\n",
    "sns.barplot(location_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_by_type = data.pivot_table(values=\"id\", index=\"location_description\", columns=\"primary_type\",\n",
    "                                   aggfunc=np.size).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_by_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering as AC\n",
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize(location_by_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Heatmap shows location frequency for each Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = AC(3).fit(df.T).labels_.argsort()\n",
    "plt.figure(figsize=(50,50))\n",
    "plt.imshow(df.T.iloc[ix,:], cmap=\"Reds\")\n",
    "plt.colorbar(fraction=0.03)\n",
    "plt.xticks(np.arange(df.shape[0]), df.index, rotation=\"vertical\")\n",
    "plt.yticks(np.arange(df.shape[1]), df.columns)\n",
    "plt.title(\"Normalized Location Frequency for each Crime\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's begin with our first Time Series Model which is ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we focus on the most common crime which is Theft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_theft = data[data[\"primary_type\"] == \"THEFT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_theft = crimes_theft.drop(\"date\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crimes_theft[\"date\"].min(), crimes_theft[\"date\"].max()\n",
    "crimes_theft = crimes_theft.sort_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_theft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_theft = data[data[\"primary_type\"] == \"THEFT\"]\n",
    "crimes_theft = crimes_theft.groupby([crimes_theft[\"date\"]]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_theft.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative sampling Based on Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plottable = crimes_theft.resample(\"MS\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plottable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of the number of crimes happening every minute from 2001 to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plottable[np.isnan(plottable)] = 1\n",
    "plottable.dropna()\n",
    "plottable[\"2013\":]\n",
    "plottable.plot(figsize=(20,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams[\"figure.figsize\"] = 18, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(plottable, model=\"additive\")\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that the model is additive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the Parameter combination to feed to the SARIMAX Function of the ARIMA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "print(\"Example of Parameter combinations for Seasonal ARIMA\")\n",
    "print(\"SARIMAX: {} x {}\".format(pdq[1], seasonal_pdq[1]))\n",
    "print(\"SARIMAX: {} x {}\".format(pdq[1], seasonal_pdq[2]))\n",
    "print(\"SARIMAX: {} x {}\".format(pdq[2], seasonal_pdq[3]))\n",
    "print(\"SARIMAX: {} x {}\".format(pdq[2], seasonal_pdq[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We should find best possible Combination with lowest AIC value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(plottable, order=param, seasonal_order=param_seasonal,\n",
    "                                           enforce_stationarity=False,\n",
    "                                           enforce_invertibility=False) #?\n",
    "            result = mod.fit()\n",
    "            print(\"ARIMA{}x{}12  -  AIC:{}\".format(param, param_seasonal, result.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing the Values with the Lowest AIC as per the above Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(plottable,\n",
    "                               order=(0, 1, 1),\n",
    "                               seasonal_order=(0, 0, 0, 12),\n",
    "                               enforce_stationarity=False,\n",
    "                               enforce_invertibility=False)\n",
    "results = mod.fit()\n",
    "print(results.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_diagnostics(figsize=(20,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = results.get_prediction(start=pd.to_datetime(\"2012-01-01\"), dynamic=False)\n",
    "\n",
    "pred_ci = pred.conf_int()\n",
    "ax = plottable[\"2001\":].plot(label=\"observed\")\n",
    "pred.predicted_mean.plot(ax=ax, label=\"One-Step ahead Forcast\",\n",
    "                        alpha=0.9,\n",
    "                        color=\"k\",\n",
    "                        figsize=(20,12))\n",
    "ax.fill_between(pred_ci.index,\n",
    "               pred_ci.iloc[:,0],\n",
    "               pred_ci.iloc[:, 1],\n",
    "               color=\"k\",\n",
    "               alpha=0.2)\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Theft Rates\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hiww\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
